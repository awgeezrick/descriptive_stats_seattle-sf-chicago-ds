{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics: Finding Meaning in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.datasets import make_blobs, make_regression, load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we're in Stage 2 of our CRISP-DM process: data understanding. We've gotten access to our data, and we want to try to understand it! Each of our data table's columns makes for its own distribution. We might have a sequence of body temperatures or house prices or birth rates or frog leg lengths or any number of other things. How, in general, can we characterize such a sequence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions and Simple Stats\n",
    "\n",
    "Let's build a simple dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([5, 5, 3, 4, 2, 5, 7, 8, 8, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One natural place to begin is to ask about where the **middle** of the data is.\n",
    "\n",
    "But what does this mean? There are three common interpretations:\n",
    "\n",
    "- arithmetic mean: sum of values / num of values\n",
    "- median: value with as many values above it as below it <br/>\n",
    "If there's an even number of values, take the arithmetic mean of the two middle values\n",
    "- mode: the most frequent value\n",
    "\n",
    "These three *could* amount to the same thing. If my dataset S = {1, 2, 2, 3}, then: <br/>\n",
    "mean(S) = median(S) = mode(S) = 2.\n",
    "\n",
    "But, given their distinct definitions, they may of course also diverge. Let's see what we have for our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(data))\n",
    "print(np.median(data))\n",
    "print(stats.mode(data)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean $\\bar{x}$ is the point that minimizes the *sum of squared differences* for a given set of data.\n",
    "\n",
    "Let's prove this:\n",
    "\n",
    "We want to find the point $k$ that minimizes $L(k) = \\Sigma^n_{i=1}(x_i-k)^2$. Now, a calculus trick, which we'll see again: To find the minimum of a function, we'll set its derivative to 0. Taking the derivative, we have:\n",
    "\n",
    "$L'(k) = -2\\Sigma^n_{i=1}(x_i-k)$.\n",
    "\n",
    "Now we solve $L'(k) = 0$ for $k$:\n",
    "\n",
    "$-2\\Sigma^n_{i=1}(x_i-k) = 0$, so <br/><br/>\n",
    "$\\Sigma^n_{i=1}(x_i-k) = 0$, so <br/><br/>\n",
    "$\\Sigma^n_{i=1}x_i = \\Sigma^n_{i=1}k = nk$, so <br/><br/>\n",
    "$k = \\frac{\\Sigma^n_{i=1}x_i}{n} = \\bar{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 5, 9]\n",
    "\n",
    "mean_cands = np.linspace(-10, 10, 201)\n",
    "\n",
    "sse = [sum([(x - cand)**2 for x in X]) for cand in mean_cands]\n",
    "\n",
    "min(sse), sse.index(min(sse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This index of 140 corresponds to -10 + 14 = 4, which is our mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(mean_cands, sse);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, the median is the point that minimizes the *sum of absolute differences*.\n",
    "\n",
    "Proof:\n",
    "\n",
    "We want to find the point $k$ that minimizes $D(k) = \\Sigma^n_{i=1}|x_i-k|$. Taking the derivative, we have:\n",
    "\n",
    "$D'(k) = \\Sigma^n_{i=1}\\frac{k-x_i}{|k-x_i|}$.\n",
    "\n",
    "Now we solve $D'(k) = 0$ for $k$:\n",
    "\n",
    "Consider the sum $\\Sigma^n_{i=1}\\frac{k-x_i}{|k-x_i|} = 0$. Ignoring the case where $k = x_i$, each of the addends in this sum is $1$ if $k\\geq x_i$ and $-1$ if not. To make this sum equal to 0, we thus want to choose $k$ such that there are the same number of $1$s and $-1$s, which means that we want to choose $k$ to be the middle number, i.e. the median.\n",
    "\n",
    "Notes:\n",
    "- if $n$ is odd, then the minimum of the function occurs not where its derivative is 0 but where it is *undefined*;\n",
    "- if $n$ is even, then *any* number between the two middle numbers will minimize our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = np.array([3, 4, 5, 6])\n",
    "def d_prime(data, k):\n",
    "    if k not in data:\n",
    "        return sum((k-data) / abs(k-data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "K = np.linspace(3, 6, 300)\n",
    "y = [d_prime(fake_data, k) for k in K]\n",
    "ax.plot(K, y)\n",
    "plt.title('Derivative of Absolute Loss')\n",
    "plt.xlabel('Placing the Median')\n",
    "plt.ylabel('Loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By conventional defintion of the median in cases of an even number of data points, we take the arithmetic mean of the two middle numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_cands = mean_cands\n",
    "\n",
    "sae = [sum([abs(x - cand) for x in X]) for cand in med_cands]\n",
    "\n",
    "min(sae), sae.index(min(sae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This index of 130 corresponds to -10 + 13 = 3, which is our median!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(med_cands, sae);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(data, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another natural question is about the **spread** of the data.\n",
    "\n",
    "The most common way of measuring this is via the standard deviation, which is a kind of measure of the \"average distance from the mean\": $\\sqrt\\frac{\\Sigma(x_i - \\bar{x})^2}{n}$.\n",
    "\n",
    "Notice that the mean is related to $\\Sigma(x_i - \\bar{x})$ while the standard deviation is related to $\\Sigma(x_i - \\bar{x})^2$. We could consider higher exponents as well. For each exponent $n>0$, we can define a related statistical **moment**. For $n=3$, the moment is called the **skewness**, which is a measure of how the mean and median diverge. For $n=4$, the moment is called the **kurtosis**, which is a measure of how many values are relatively far from the mean.\n",
    "\n",
    "There are a few different definitions of skewness and kurtosis that are commonly used, but the basic quantities are:\n",
    "\n",
    "- $\\frac{\\Sigma(x_i - \\bar{x})^3}{n\\sigma^3}$ (for skewness); and\n",
    "- $\\frac{\\Sigma(x_i - \\bar{x})^4}{n\\sigma^4}$ (for kurtosis).\n",
    "\n",
    "For more on statistical moments, see [here](https://www.statisticshowto.datasciencecentral.com/what-is-a-moment/) and [here](https://www.spcforexcel.com/knowledge/basic-statistics/are-skewness-and-kurtosis-useful-statistics).\n",
    "\n",
    "One might also ask about the general **shape** or **distribution** of the data. Are most data points clustered around the mean? Are they distributed symmetrically? Is the mean actually not very common? Let's look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-3, 3, 40)\n",
    "y = stats.norm.pdf(X) + 0.05 * np.random.rand(40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.plot(X, y, lw=5)\n",
    "ax.vlines(x=0, ymin=0, ymax=0.4)\n",
    "plt.title('Symmetric Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 40)\n",
    "y = stats.expon.pdf(X) + 0.05 * np.random.rand(40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.plot(X, y, lw=5)\n",
    "plt.title('Asymmetric Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 1, 40)\n",
    "y = stats.uniform.pdf(X) + 0.05 * np.random.rand(40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.plot(X, y, lw=5)\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.title('Flat Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-5, 5, 40)\n",
    "y = stats.norm.pdf(X, loc=-2) + stats.norm.pdf(X, loc=2)\\\n",
    "+ 0.05 * np.random.rand(40)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "ax.plot(X, y, lw=5)\n",
    "plt.title('Bimodal Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "One natural way of visualizing a dataset is to construct a histogram, which is a simple count of the different values existing in the dataset.\n",
    "\n",
    "Very often there will be many, many distinct values, especially if the dimension in question is a continuum. In that case, one will often need to make a decision about how many **bins** to use in constructing the histogram, i.e. about how to group the different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=20)\n",
    "plt.title('Counts, 20 Bins');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=10)\n",
    "plt.title('Counts, 10 Bins');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=5)\n",
    "plt.title('Counts, 5 Bins');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(data, bins=3)\n",
    "plt.title('Counts, 3 Bins');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn.datasets\n",
    "\n",
    "Sklearn's datasets module has lots of tools to generate your own (fake) data. These can be very useful when evaluating a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, c = make_blobs(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=c)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Blob Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = X[:, 0], X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's describe x1 and x2 in statistical terms!\n",
    "\n",
    "print(f\"The maximum of x1 is {x1.max()}.\")\n",
    "print(f\"The average of x1 is {x1.mean()}.\")\n",
    "print(f\"The minimum of x1 is {x1.min()}.\")\n",
    "print(f\"The standard deviation of x1 is {x1.std()}.\")\n",
    "print(f\"The interquartile range of x1 is\\\n",
    "{np.percentile(x1, q=75) - np.percentile(x1, q=25)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The maximum of x2 is {x2.max()}.\")\n",
    "print(f\"The average of x2 is {x2.mean()}.\")\n",
    "print(f\"The minimum of x2 is {x2.min()}.\")\n",
    "print(f\"The standard deviation of x2 is {x2.std()}.\")\n",
    "print(f\"The interquartile range of x2 is\\\n",
    "{np.percentile(x2, q=75) - np.percentile(x2, q=25)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(x1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(x2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(x1)\n",
    "ax.hist(x2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multiple plots on the same axis, it's often a good idea to reduce the opacity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(x1, alpha=0.7)\n",
    "ax.hist(x2, alpha=0.7);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].hist(x1)\n",
    "ax[1].hist(x2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.concatenate([X, c.reshape(-1, 1)], axis=1),\n",
    "                  columns=['x1', 'x2', 'y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "ax[0][0].title.set_text('blobs')\n",
    "ax[0][0].scatter(x1, x2, c=c);\n",
    "ax[0][1].title.set_text('bars')\n",
    "ax[0][1].barh(['alvin', 'simon', 'theodore'], ['happy', 'thrilled', 'elated'])\n",
    "ax[1][0].title.set_text('x1 box and whisker')\n",
    "ax[1][0].boxplot(x1)\n",
    "ax[1][1].title.set_text('x2 box and whisker')\n",
    "ax[1][1].boxplot(x2);\n",
    "\n",
    "sns.boxplot(x1, orient='v');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, T = make_regression(n_features=1, noise = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(P, T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rock Music Data\n",
    "\n",
    "Let's see what stats or graphs we can pull out of this dataset about rock songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "songs = pd.read_csv('classic-rock-song-list.csv')\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could make a histogram of the song play counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs['PlayCount'].sort_values().hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also try grouping by artist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs.groupby('ARTIST CLEAN').count()['Song Clean'].sort_values(ascending=False)\n",
    "\n",
    "nums_sorted = songs.groupby('ARTIST CLEAN')\\\n",
    ".count()['Song Clean'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "ax.scatter(nums_sorted[:10].index, nums_sorted[:10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_sorted.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums_sorted.kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack([X, y.reshape(-1, 1)]),\n",
    "                  columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'spec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spec'] = df['spec'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    "df['spec'] = df['spec'].map(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Seaborn Tools\n",
    "\n",
    "### Categorical Plots\n",
    "\n",
    "#### Swarm Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"spec\", y=\"sepal_wid\",\n",
    "            kind='swarm', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='petal_len', y='spec',\n",
    "            kind='violin', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='spec', y='sepal_wid',\n",
    "           kind='point', data=df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"sepal_len\", y=\"sepal_wid\", col=\"spec\",\n",
    "            hue=\"petal_len\", size=\"petal_wid\",\n",
    "            data=df);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
